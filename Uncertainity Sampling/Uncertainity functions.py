# -*- coding: utf-8 -*-
"""Sea_Uncertainity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sGl7BagzvFICq4JAa_14PXCX7qCf_EeY
"""

pip install river

# Commented out IPython magic to ensure Python compatibility.
from river import evaluate
from river import metrics
from river import tree
from river import datasets
import matplotlib.pyplot as plt
# %matplotlib inline
import pandas as pd

"""# Uncertanity Sampling"""

def uncertainitySampWithPlot(df, thresh,model):
  column_names = []
  for col in df.columns:
    column_names.append(col)
  z = []
  for i in range(df.shape[0]):
    z.append((list(df.loc[i][0:df.shape[1]-1]),df.loc[i][df.shape[1]-1]))
  prob1 = []
  prob0 = []
  diff = []
  acc=[]
  correct_cnt = 0
  training_data = 20
  total_data = 0
  for x in range(len(z)):
      a = {}
      data = z[x][0]
      for p in range(len(column_names)-1):
        a[column_names[p]]=data[p]
      b = z[x][1]
      total_data+= 1 
      if x<20:
          model=model.learn_one(a,b)
      else:
          pred = model.predict_one(a)
          if pred == b:
              acc.append(1)
              correct_cnt += 1
          else:
              acc.append(0)
          prob_0 = model.predict_proba_one(a)[0]
          prob_1 = model.predict_proba_one(a)[1]
          prob1.append(prob_1)
          prob0.append(prob_0)
          diff.append(prob_1-prob_0)
          if abs(prob_0-prob_1)<= thresh:
              model=model.learn_one(a,b)
              training_data += 1
  from statistics import mean
  import math
  accuracy_measure=[]
  for p in range(math.floor(len(z)/1000)):
    accuracy_measure.append(mean(acc[1:(p+1)*1000]))
  import matplotlib.pyplot as plt

  k = range(1,math.floor(len(z)/1000)+1)
  plt.figure(figsize=(10,10))
  plt.plot(k,accuracy_measure,label="Uncertainity Sampling")
  return(plt)

def uncertainitySamp(df, thresh,model):
  column_names = []
  for col in df.columns:
    column_names.append(col)
  z = []
  for i in range(df.shape[0]):
    z.append((list(df.loc[i][0:df.shape[1]-1]),df.loc[i][df.shape[1]-1]))
  prob1 = []
  prob0 = []
  diff = []
  acc=[]
  correct_cnt = 0
  training_data = 20
  total_data = 0
  for x in range(len(z)):
      a = {}
      data = z[x][0]
      for p in range(len(column_names)-1):
        a[column_names[p]]=data[p]
      b = z[x][1]
      total_data+= 1 
      if x<20:
          model=model.learn_one(a,b)
      else:
          pred = model.predict_one(a)
          if pred == b:
              acc.append(1)
              correct_cnt += 1
          else:
              acc.append(0)
          prob_0 = model.predict_proba_one(a)[0]
          prob_1 = model.predict_proba_one(a)[1]
          prob1.append(prob_1)
          prob0.append(prob_0)
          diff.append(prob_1-prob_0)
          if abs(prob_0-prob_1)<= thresh:
              model=model.learn_one(a,b)
              training_data += 1
  from statistics import mean
  import math
  accuracy_measure=[]
  for p in range(math.floor(len(z)/1000)):
    accuracy_measure.append(mean(acc[1:(p+1)*1000]))
  return(accuracy_measure)

